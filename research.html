<style>
  .card {
    background: #ffffff;
    border: 1px solid #ddd;
    border-radius: 10px;
    padding: 20px;
    margin-bottom: 25px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
  }

  h3 {
    margin-top: 0;
    color: #333;
  }

  ul {
    padding-left: 20px;
  }
</style>

<!-- UROP, HKUST (Dan Xu) -->
<div class="card">
  <h3>UROP, HKUST — Advisor: <a href="https://cse.hkust.edu.hk/admin/people/faculty/profile/danxu" target="_blank">Dan Xu</a> (Jun–Aug 2023)</h3>
  <ul>
    <li>Developed a <strong>conditional diffusion model</strong> for monocular depth estimation from RGB images.</li>
    <li>Built an <strong>Efficient-UNet</strong> with residuals and optimized up/down-sampling to preserve depth structures.</li>
    <li>Designed a two-step <strong>depth infilling algorithm</strong> for handling missing values in NYU Depth V2.</li>
    <li>Applied <strong>Step-Unrolled Denoising (SUD)</strong> and masked losses to mitigate distribution shift on incomplete maps.</li>
    <li>Finetuned under compute limits to improve depth completeness and global scene consistency.</li>
  </ul>
</div>

<!-- UROP, HKUST (Yu Hu) -->
<div class="card">
  <h3>UROP, HKUST — Advisor: <a href="https://mahy.people.ust.hk/" target="_blank">Yu Hu</a> (Sep–Dec 2023)</h3>
  <ul>
    <li>Modeled <strong>brain-wide neural dynamics in zebrafish</strong> using a recurrent <strong>Firing Rate Network</strong>.</li>
    <li>Implemented <strong>firing rate evolution equations</strong> with Poisson inputs and synaptic filtering.</li>
    <li>Simulated large-scale circuits and trained synaptic connectivity via <strong>Partial In-Network Training (PINning)</strong> with Recursive Least Squares.</li>
    <li>Analyzed structural patterns in connectivity to identify potential subnetworks and functional motifs.</li>
  </ul>
</div>

<!-- KnowComp Group, HKUST -->
<div class="card">
  <h3>KnowComp Group, HKUST — Advisor: <a href="https://www.cse.ust.hk/~yqsong/" target="_blank">Yangqiu Song</a> (Feb–Sep 2024)</h3>
  <ul>
    <li><strong>BrainASER (Led by <a href="https://scholar.google.com/citations?user=1dteS3wAAAAJ&hl=zh-CN" target="_blank">Haochen Shi</a>)</strong>: Studied correspondences between neural activity and <strong>knowledge graph</strong> structures.</li>
    <li>Aligned fMRI data (Narratives dataset) with story-based stimuli to analyze brain-language interactions.</li>
    <li>Developed brain-inspired representations for downstream NLP tasks leveraging structural similarities with knowledge graphs.</li>
    <li><strong>IntentionQA (Led by <a href="https://wenwen-d.github.io/" target="_blank">Wenxuan Ding</a>)</strong>: Built a benchmark to evaluate LMs’ understanding of purchase intentions in E-commerce.</li>
    <li>Preprocessed data, aligned products with intentions via ASER, and generated negative distractors.</li>
    <li>Evaluated 19 LMs, identifying reasoning limitations in predicting user intent and handling real-world E-commerce scenarios.</li>
  </ul>
</div>

<!-- Washington University in St. Louis -->
<div class="card">
  <h3>Washington University in St. Louis — Advisor: <a href="https://www.cse.wustl.edu/~m.neumann/" target="_blank">Marion Neumann</a> (Sep–Dec 2024)</h3>
  <ul>
    <li>Developed an <strong>inductive recommendation system</strong> for new e-commerce products using the Amazon Co-Purchasing Network.</li>
    <li>Constructed a co-purchasing graph with 519K nodes and 964K edges, encoding product features, categories, and structural metrics.</li>
    <li>Applied a <strong>modified GraphSAGE</strong> for link prediction to enable recommendations for isolated nodes with limited data.</li>
    <li>Designed scalable, real-time updates for adaptive recommendations on dynamic product catalogs.</li>
  </ul>
</div>

<!-- RenLab, HKUST (Yi Fung) -->
<div class="card">
  <h3>RenLab, HKUST — Advisor: <a href="https://mayrfung.github.io/" target="_blank">Yi R. (May) Fung</a> (Feb–Jun 2025)</h3>
  <ul>
    <li>Researched <strong>text-guided medical image editing</strong> and developed evaluation frameworks for multimodal models.</li>
    <li>Contributed to <strong>MedEBench</strong>, a benchmark of 1,182 clinical image-prompt triplets across 70 tasks and 13 anatomical regions.</li>
    <li>Designed clinically grounded metrics for <strong>Editing Accuracy, Contextual Preservation, and Visual Quality</strong> using ROI-based assessments and attention-grounding analysis.</li>
    <li>Evaluated seven state-of-the-art models, identifying common failure patterns in medically meaningful edits.</li>
  </ul>
</div>

<!-- RenLab, HKUST (Yi Fung & Li Yuxin) -->
<div class="card">
  <h3>RenLab, HKUST — Advisor: <a href="https://mayrfung.github.io/" target="_blank">Yi R. (May) Fung</a>; (May 2025 – Current)</h3>
  <ul>
    <li>Formalize physics concepts and statements into <strong>Lean</strong>, enabling rigorous machine-verified reasoning.</li>
    <li>Develop representations of laws and principles to facilitate automated derivations and proofs.</li>
  </ul>
</div>
<!-- Collaborator: <a href="https://yuxin.li/" target="_blank">Li Yuxin</a> -->